{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9366ff-6d3a-4d9f-ba24-940ed6a30f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:\n",
    "# A* Search Algorithm for Route Finding Problem\n",
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def a_star_search(graph, heuristics, start, goal):\n",
    "    pq = PriorityQueue()\n",
    "    pq.put((0, start))\n",
    "    g_cost = {start: 0}\n",
    "    parent = {start: None}\n",
    "\n",
    "    while not pq.empty():\n",
    "        cost, node = pq.get()\n",
    "\n",
    "        if node == goal:\n",
    "            break\n",
    "\n",
    "        for neighbor, distance in graph[node].items():\n",
    "            new_cost = g_cost[node] + distance\n",
    "            if neighbor not in g_cost or new_cost < g_cost[neighbor]:\n",
    "                g_cost[neighbor] = new_cost\n",
    "                priority = new_cost + heuristics[neighbor]\n",
    "                pq.put((priority, neighbor))\n",
    "                parent[neighbor] = node\n",
    "\n",
    "    # Reconstruct path\n",
    "    path = []\n",
    "    n = goal\n",
    "    while n is not None:\n",
    "        path.append(n)\n",
    "        n = parent[n]\n",
    "    path.reverse()\n",
    "\n",
    "    return path, g_cost[goal]\n",
    "\n",
    "\n",
    "# --- Example graph (Real-life: city distances) ---\n",
    "graph = {\n",
    "    'Pune': {'Mumbai': 120, 'Nashik': 210, 'Satara': 110},\n",
    "    'Mumbai': {'Pune': 120, 'Nashik': 160},\n",
    "    'Nashik': {'Pune': 210, 'Mumbai': 160, 'Nagpur': 700},\n",
    "    'Satara': {'Pune': 110, 'Kolhapur': 130},\n",
    "    'Kolhapur': {'Satara': 130, 'Goa': 200},\n",
    "    'Nagpur': {'Nashik': 700, 'Hyderabad': 500},\n",
    "    'Goa': {'Kolhapur': 200},\n",
    "    'Hyderabad': {'Nagpur': 500}\n",
    "}\n",
    "\n",
    "# --- Heuristic values (straight-line estimate to goal) ---\n",
    "heuristics = {\n",
    "    'Pune': 400, 'Mumbai': 300, 'Nashik': 500,\n",
    "    'Satara': 350, 'Kolhapur': 200, 'Nagpur': 800,\n",
    "    'Goa': 0, 'Hyderabad': 600\n",
    "}\n",
    "\n",
    "# --- Run A* Search ---\n",
    "path, cost = a_star_search(graph, heuristics, 'Pune', 'Goa')\n",
    "\n",
    "print(\"Shortest Path:\", \" â†’ \".join(path))\n",
    "print(\"Total Distance:\", cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26f693b5-9e24-4cea-bb54-df3dd0319f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest Path: [(0, 0), (1, 0), (2, 0), (2, 1), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]\n",
      "Number of Steps: 8\n"
     ]
    }
   ],
   "source": [
    "# 2:\n",
    "from collections import deque\n",
    "\n",
    "def bfs_shortest_path(maze, start, goal):\n",
    "    # 0 = free cell, 1 = obstacle\n",
    "    rows, cols = len(maze), len(maze[0])\n",
    "    moves = [(-1,0), (1,0), (0,-1), (0,1)]  # up, down, left, right\n",
    "\n",
    "    queue = deque([[start]])   # store only the path\n",
    "    visited = {start}\n",
    "\n",
    "    while queue:\n",
    "        path = queue.popleft()\n",
    "        r, c = path[-1]\n",
    "\n",
    "        if (r, c) == goal:\n",
    "            return path  # shortest path found\n",
    "\n",
    "        for dr, dc in moves:\n",
    "            nr, nc = r + dr, c + dc\n",
    "            if 0 <= nr < rows and 0 <= nc < cols and maze[nr][nc] == 0 and (nr, nc) not in visited:\n",
    "                visited.add((nr, nc))\n",
    "                queue.append(path + [(nr, nc)])\n",
    "    return None\n",
    "\n",
    "# --- Example Maze ---\n",
    "maze = [\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0]\n",
    "]\n",
    "\n",
    "start, goal = (0, 0), (4, 4)\n",
    "path = bfs_shortest_path(maze, start, goal)\n",
    "\n",
    "if path:\n",
    "    print(\"Shortest Path:\", path)\n",
    "    print(\"Number of Steps:\", len(path) - 1)\n",
    "else:\n",
    "    print(\"No path found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f00141c-268f-48b4-b8be-517931ee34ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS Traversal Order:\n",
      "Start â†’ A â†’ C â†’ D â†’ F â†’ Goal â†’ B â†’ E\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "# Depth-First Search (DFS) traversal on a graph\n",
    "\n",
    "def dfs(graph, node, visited=None):\n",
    "    if visited is None:\n",
    "        visited = []\n",
    "    visited.append(node)\n",
    "\n",
    "    # Visit each connected node (neighbor)\n",
    "    for neighbor in graph[node]:\n",
    "        if neighbor not in visited:\n",
    "            dfs(graph, neighbor, visited)\n",
    "\n",
    "    return visited\n",
    "\n",
    "\n",
    "# --- Example Game Map Graph ---\n",
    "game_map = {\n",
    "    'Start': ['A', 'B'],\n",
    "    'A': ['C', 'D'],\n",
    "    'B': ['E'],\n",
    "    'C': [],\n",
    "    'D': ['F'],\n",
    "    'E': ['F'],\n",
    "    'F': ['Goal'],\n",
    "    'Goal': []\n",
    "}\n",
    "\n",
    "# --- Run DFS ---\n",
    "order = dfs(game_map, 'Start')\n",
    "\n",
    "# --- Display Result ---\n",
    "print(\"DFS Traversal Order:\")\n",
    "print(\" â†’ \".join(order))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f11daa67-8372-48d0-85ce-ac7732ecd033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest path found by A*:\n",
      " [(0, 0), (1, 0), (2, 0), (2, 1), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]\n",
      "Steps: 8\n"
     ]
    }
   ],
   "source": [
    "# 4:\n",
    "import heapq\n",
    "\n",
    "# --- Heuristic Function: Manhattan Distance ---\n",
    "def heuristic(a, b):\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "# --- A* Search Algorithm ---\n",
    "def astar(maze, start, goal):\n",
    "    rows, cols = len(maze), len(maze[0])\n",
    "    open_set = [(0, start)]  # (f_cost, node)\n",
    "    came_from = {}\n",
    "    g_score = {start: 0}\n",
    "\n",
    "    while open_set:\n",
    "        _, current = heapq.heappop(open_set)\n",
    "\n",
    "        if current == goal:  # reconstruct path\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            path.append(start)\n",
    "            return path[::-1]\n",
    "\n",
    "        # 4 directions: up, down, left, right\n",
    "        for dr, dc in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "            r, c = current[0] + dr, current[1] + dc\n",
    "            if not (0 <= r < rows and 0 <= c < cols):  # bounds\n",
    "                continue\n",
    "            if maze[r][c] == 1:  # wall\n",
    "                continue\n",
    "\n",
    "            neighbor = (r, c)\n",
    "            new_cost = g_score[current] + 1\n",
    "            if neighbor not in g_score or new_cost < g_score[neighbor]:\n",
    "                g_score[neighbor] = new_cost\n",
    "                f_score = new_cost + heuristic(neighbor, goal)\n",
    "                heapq.heappush(open_set, (f_score, neighbor))\n",
    "                came_from[neighbor] = current\n",
    "    return None\n",
    "\n",
    "# --- Example Maze ---\n",
    "maze = [\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0]\n",
    "]\n",
    "\n",
    "start, goal = (0, 0), (4, 4)\n",
    "path = astar(maze, start, goal)\n",
    "\n",
    "# --- Output ---\n",
    "if path:\n",
    "    print(\"Shortest path found by A*:\\n\", path)\n",
    "    print(\"Steps:\", len(path) - 1)\n",
    "else:\n",
    "    print(\"No path found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9432fe-5665-42b4-8cd6-0101a1a9e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "import heapq\n",
    "\n",
    "# --- Heuristic: Manhattan Distance ---\n",
    "def manhattan(puzzle, goal):\n",
    "    dist = 0\n",
    "    for i in range(9):\n",
    "        if puzzle[i] == 0: \n",
    "            continue\n",
    "        x1, y1 = divmod(i, 3)\n",
    "        x2, y2 = divmod(goal.index(puzzle[i]), 3)\n",
    "        dist += abs(x1 - x2) + abs(y1 - y2)\n",
    "    return dist\n",
    "\n",
    "# --- Get Possible Moves ---\n",
    "def get_neighbors(state):\n",
    "    i = state.index(0)\n",
    "    r, c = divmod(i, 3)\n",
    "    moves = []\n",
    "    for dr, dc in [(-1,0),(1,0),(0,-1),(0,1)]:\n",
    "        nr, nc = r+dr, c+dc\n",
    "        if 0 <= nr < 3 and 0 <= nc < 3:\n",
    "            j = nr*3 + nc\n",
    "            new_state = list(state)\n",
    "            new_state[i], new_state[j] = new_state[j], new_state[i]\n",
    "            moves.append(tuple(new_state))\n",
    "    return moves\n",
    "\n",
    "# --- Reconstruct Path ---\n",
    "def reconstruct(came_from, current):\n",
    "    path = [current]\n",
    "    while current in came_from:\n",
    "        current = came_from[current]\n",
    "        path.append(current)\n",
    "    return path[::-1]\n",
    "\n",
    "# --- A* Algorithm ---\n",
    "def a_star(start, goal):\n",
    "    open_heap = [(manhattan(start, goal), start)]\n",
    "    came_from = {}\n",
    "    g = {start: 0}\n",
    "\n",
    "    while open_heap:\n",
    "        _, current = heapq.heappop(open_heap)\n",
    "        if current == goal:\n",
    "            return reconstruct(came_from, current)\n",
    "\n",
    "        for neighbor in get_neighbors(current):\n",
    "            tentative = g[current] + 1\n",
    "            if neighbor not in g or tentative < g[neighbor]:\n",
    "                g[neighbor] = tentative\n",
    "                f = tentative + manhattan(neighbor, goal)\n",
    "                heapq.heappush(open_heap, (f, neighbor))\n",
    "                came_from[neighbor] = current\n",
    "    return None\n",
    "\n",
    "# --- Example ---\n",
    "start = (1, 2, 3,\n",
    "         4, 0, 5,\n",
    "         6, 7, 8)\n",
    "\n",
    "goal = (1, 2, 3,\n",
    "        4, 5, 6,\n",
    "        7, 8, 0)\n",
    "\n",
    "path = a_star(start, goal)\n",
    "\n",
    "# --- Print Solution ---\n",
    "if path:\n",
    "    print(f\"Puzzle solved in {len(path)-1} moves!\\n\")\n",
    "    for step in path:\n",
    "        print(step[0:3])\n",
    "        print(step[3:6])\n",
    "        print(step[6:9])\n",
    "        print()\n",
    "else:\n",
    "    print(\"No solution found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c00af4e-00b6-443a-9e59-c425cb48ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ® Welcome to Tic-Tac-Toe ðŸŽ®\n",
      "\n",
      "Current Board:\n",
      "   |   |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "\n",
      "Player X's turn:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter row (0-2):  0\n",
      "Enter column (0-2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      "   | X |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "\n",
      "Player O's turn:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter row (0-2):  0\n",
      "Enter column (0-2):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      " O | X |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "\n",
      "Player X's turn:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter row (0-2):  0\n",
      "Enter column (0-2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      " O | X | X\n",
      "---+---+---\n",
      "   |   |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "\n",
      "Player O's turn:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter row (0-2):  1\n",
      "Enter column (0-2):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      " O | X | X\n",
      "---+---+---\n",
      " O |   |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "\n",
      "Player X's turn:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter row (0-2):  1\n",
      "Enter column (0-2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      " O | X | X\n",
      "---+---+---\n",
      " O | X |  \n",
      "---+---+---\n",
      "   |   |  \n",
      "\n",
      "Player O's turn:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter row (0-2):  1\n",
      "Enter column (0-2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      " O | X | X\n",
      "---+---+---\n",
      " O | X | O\n",
      "---+---+---\n",
      "   |   |  \n",
      "\n",
      "Player X's turn:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter row (0-2):  2\n",
      "Enter column (0-2):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      " O | X | X\n",
      "---+---+---\n",
      " O | X | O\n",
      "---+---+---\n",
      " X |   |  \n",
      "\n",
      "ðŸ† Player X wins!\n"
     ]
    }
   ],
   "source": [
    "#6:Tic tac toe\n",
    "def print_board(board):\n",
    "    print(\"\\nCurrent Board:\")\n",
    "    for i in range(3):\n",
    "        print(\" \" + \" | \".join(board[i]))\n",
    "        if i < 2:\n",
    "            print(\"---+---+---\")\n",
    "\n",
    "def check_winner(board):\n",
    "    # Rows and Columns\n",
    "    for i in range(3):\n",
    "        if board[i][0] == board[i][1] == board[i][2] != \" \":\n",
    "            return board[i][0]\n",
    "        if board[0][i] == board[1][i] == board[2][i] != \" \":\n",
    "            return board[0][i]\n",
    "    # Diagonals\n",
    "    if board[0][0] == board[1][1] == board[2][2] != \" \":\n",
    "        return board[0][0]\n",
    "    if board[0][2] == board[1][1] == board[2][0] != \" \":\n",
    "        return board[0][2]\n",
    "    return None\n",
    "\n",
    "def is_full(board):\n",
    "    return all(cell != \" \" for row in board for cell in row)\n",
    "\n",
    "def play_game():\n",
    "    board = [[\" \"]*3 for _ in range(3)]\n",
    "    player = \"X\"\n",
    "    print(\"ðŸŽ® Welcome to Tic-Tac-Toe ðŸŽ®\")\n",
    "    print_board(board)\n",
    "\n",
    "    while True:\n",
    "        print(f\"\\nPlayer {player}'s turn:\")\n",
    "        try:\n",
    "            row = int(input(\"Enter row (0-2): \"))\n",
    "            col = int(input(\"Enter column (0-2): \"))\n",
    "        except ValueError:\n",
    "            print(\"Enter valid numbers only!\")\n",
    "            continue\n",
    "\n",
    "        if not (0 <= row < 3 and 0 <= col < 3):\n",
    "            print(\"Invalid position! Try again.\")\n",
    "            continue\n",
    "        if board[row][col] != \" \":\n",
    "            print(\"Cell already taken! Try again.\")\n",
    "            continue\n",
    "\n",
    "        board[row][col] = player\n",
    "        print_board(board)\n",
    "\n",
    "        if check_winner(board):\n",
    "            print(f\"\\nðŸ† Player {player} wins!\")\n",
    "            break\n",
    "        if is_full(board):\n",
    "            print(\"\\nðŸ¤ It's a draw!\")\n",
    "            break\n",
    "\n",
    "        player = \"O\" if player == \"X\" else \"X\"\n",
    "\n",
    "# Run Game\n",
    "play_game()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167887c4-0e9a-4b82-8653-af3f7e006f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7: Tower of Hanoi using Recursion\n",
    "\n",
    "def hanoi(n, source, helper, destination):\n",
    "    if n == 1:\n",
    "        print(f\"Move disk 1 from {source} â†’ {destination}\")\n",
    "        return\n",
    "    # Move n-1 disks from source to helper\n",
    "    hanoi(n - 1, source, destination, helper)\n",
    "    # Move the largest disk from source to destination\n",
    "    print(f\"Move disk {n} from {source} â†’ {destination}\")\n",
    "    # Move n-1 disks from helper to destination\n",
    "    hanoi(n - 1, helper, source, destination)\n",
    "\n",
    "# --- Main Program ---\n",
    "n = int(input(\"Enter number of disks: \"))\n",
    "print(\"\\nSequence of moves:\")\n",
    "hanoi(n, 'A', 'B', 'C')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d686b252-f507-4b75-aa6c-a98e8e3b2a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps to reach the target:\n",
      "\n",
      "(0, 0)\n",
      "(4, 0)\n",
      "(0, 3)\n",
      "(1, 3)\n",
      "(4, 3)\n",
      "(3, 0)\n",
      "(1, 0)\n",
      "(3, 3)\n",
      "(0, 1)\n",
      "(4, 2)\n",
      "\n",
      " Reached the target amount!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8:\n",
    "from collections import deque\n",
    "\n",
    "def water_jug_bfs(jug1_capacity, jug2_capacity, target):\n",
    "    visited = set()\n",
    "    q = deque([(0, 0)])  # both jugs empty initially\n",
    "    visited.add((0, 0))\n",
    "\n",
    "    print(\"Steps to reach the target:\\n\")\n",
    "\n",
    "    while q:\n",
    "        x, y = q.popleft()\n",
    "        print(f\"({x}, {y})\")\n",
    "\n",
    "        # Goal check\n",
    "        if x == target or y == target:\n",
    "            print(\"\\n Reached the target amount!\")\n",
    "            return True\n",
    "\n",
    "        # Generate next possible states\n",
    "        next_states = set()\n",
    "\n",
    "        # 1. Fill Jug1 or Jug2\n",
    "        next_states.add((jug1_capacity, y))\n",
    "        next_states.add((x, jug2_capacity))\n",
    "\n",
    "        # 2. Empty Jug1 or Jug2\n",
    "        next_states.add((0, y))\n",
    "        next_states.add((x, 0))\n",
    "\n",
    "        # 3. Pour Jug1 â†’ Jug2\n",
    "        pour = min(x, jug2_capacity - y)\n",
    "        next_states.add((x - pour, y + pour))\n",
    "\n",
    "        # 4. Pour Jug2 â†’ Jug1\n",
    "        pour = min(y, jug1_capacity - x)\n",
    "        next_states.add((x + pour, y - pour))\n",
    "\n",
    "        # Add all unvisited states to the queue\n",
    "        for state in next_states:\n",
    "            if state not in visited:\n",
    "                visited.add(state)\n",
    "                q.append(state)\n",
    "\n",
    "    print(\"\\n No solution possible.\")\n",
    "    return False\n",
    "\n",
    "\n",
    "# --- Example ---\n",
    "jug1 = 4\n",
    "jug2 = 3\n",
    "target = 2\n",
    "water_jug_bfs(jug1, jug2, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c81e5a-9afa-4f78-917b-1fad7c16f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9: \n",
    "# Uber Ride Price Prediction using PCA and EDA (No xlrd required)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# --- STEP 1: Load dataset (save your .xls file as .csv first) ---\n",
    "# Example path: C:\\Users\\Documents\\AIML\\uber_data.csv\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\uber_data.csv\")\n",
    "\n",
    "# --- STEP 2: Basic EDA ---\n",
    "print(\"\\nFirst 5 Rows:\\n\", df.head())\n",
    "print(\"\\nDataset Info:\\n\")\n",
    "print(df.info())\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# --- STEP 3: Correlation Heatmap ---\n",
    "plt.matshow(df.corr(), cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# --- STEP 4: Define Features (X) and Target (y) ---\n",
    "# Change 'price' to your target column name if different\n",
    "X = df.drop(columns=['price'])\n",
    "y = df['price']\n",
    "\n",
    "# --- STEP 5: Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- STEP 6: Standardize Features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- STEP 7: Model without PCA ---\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "y_pred1 = model1.predict(X_test_scaled)\n",
    "\n",
    "# --- STEP 8: Apply PCA (reduce to 2 components) ---\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# --- STEP 9: Model with PCA ---\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train_pca, y_train)\n",
    "y_pred2 = model2.predict(X_test_pca)\n",
    "\n",
    "# --- STEP 10: Compare Performance ---\n",
    "print(\"\\nModel Performance (Without PCA):\")\n",
    "print(\"RÂ² Score :\", round(r2_score(y_test, y_pred1), 3))\n",
    "print(\"RMSE :\", round(mean_squared_error(y_test, y_pred1, squared=False), 3))\n",
    "print(\"MAE :\", round(mean_absolute_error(y_test, y_pred1), 3))\n",
    "\n",
    "print(\"\\nModel Performance (With PCA):\")\n",
    "print(\"RÂ² Score :\", round(r2_score(y_test, y_pred2), 3))\n",
    "print(\"RMSE :\", round(mean_squared_error(y_test, y_pred2, squared=False), 3))\n",
    "print(\"MAE :\", round(mean_absolute_error(y_test, y_pred2), 3))\n",
    "\n",
    "# --- STEP 11: PCA Visualization ---\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis')\n",
    "plt.title(\"Data after PCA (2 Components)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbae1f9-2206-4c29-b1b8-820f1ade3259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bea190-fa81-4a44-b8f0-21cb09a4240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10:\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\Documents\\AIML\\uber_9_10.xls\")\n",
    "\n",
    "# --- EDA ---\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.describe())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# --- Features and Target ---\n",
    "X = df.drop('price', axis=1)   # change 'price' if column name differs\n",
    "y = df['price']\n",
    "\n",
    "# --- Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# --- Scale and Apply PCA ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# --- Train model ---\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# --- Evaluate ---\n",
    "print(\"\\nModel Evaluation using PCA:\")\n",
    "print(\"RÂ² Score :\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE :\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"MAE :\", mean_absolute_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ea5cd-0a70-484b-ae36-5c7c4785ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\house_data.csv\")  # change name if needed\n",
    "print(df.head())\n",
    "\n",
    "# --- Features and Target ---\n",
    "X = df[['area', 'bedrooms', 'location']]   # independent variables\n",
    "y = df['price']                            # target variable\n",
    "\n",
    "# --- Preprocessing: OneHotEncode location (categorical) ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(), ['location'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# --- Model pipeline ---\n",
    "model = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# --- Apply K-Fold Cross Validation ---\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')\n",
    "\n",
    "# --- Results ---\n",
    "print(\"\\nRÂ² scores for each fold:\", scores)\n",
    "print(\"Average RÂ² score:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780c5b6-f7cf-4112-839d-3aa3aadfd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\student_data.csv\")  # update name if needed\n",
    "print(df.head())\n",
    "\n",
    "# --- Select relevant columns ---\n",
    "X = df['study_hours'].values\n",
    "y = df['final_exam_score'].values\n",
    "\n",
    "# --- Manual Linear Regression ---\n",
    "n = len(X)\n",
    "x_mean = np.mean(X)\n",
    "y_mean = np.mean(y)\n",
    "\n",
    "# Calculate slope (m) and intercept (c)\n",
    "num = np.sum((X - x_mean) * (y - y_mean))\n",
    "den = np.sum((X - x_mean)**2)\n",
    "m = num / den\n",
    "c = y_mean - m * x_mean\n",
    "\n",
    "# --- Prediction ---\n",
    "y_pred = m * X + c\n",
    "\n",
    "# --- Evaluation ---\n",
    "mse = np.mean((y - y_pred)**2)\n",
    "r2 = 1 - np.sum((y - y_pred)**2) / np.sum((y - y_mean)**2)\n",
    "\n",
    "# --- Output ---\n",
    "print(\"\\nEquation: y =\", round(m, 3), \"* x +\", round(c, 3))\n",
    "print(\"Mean Squared Error (MSE):\", round(mse, 3))\n",
    "print(\"RÂ² Score:\", round(r2, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7a39e-e57c-41f8-94b8-017727a8f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\student_data.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# --- Features and Target ---\n",
    "X = df[['study_hours', 'attendance', 'internal_marks']]\n",
    "y = df['final_exam_score']\n",
    "\n",
    "# --- Model ---\n",
    "model = LinearRegression()\n",
    "\n",
    "# --- 5-Fold Cross-Validation ---\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')\n",
    "\n",
    "# --- Results ---\n",
    "print(\"\\nRÂ² Scores for each fold:\", scores)\n",
    "print(\"Average RÂ² Score:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ba3dc-a1a0-4b98-a6e9-cc77fc925750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\Documents\\AIML\\IT_salary_data.xlsx\")  # update path if needed\n",
    "print(df.head())\n",
    "\n",
    "# --- Features and Target ---\n",
    "X = df[['experience', 'education', 'skills']]   # independent variables\n",
    "y = df['salary']                               # target variable\n",
    "\n",
    "# --- Encode categorical columns (education, skills) ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(), ['education', 'skills'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# --- Build model pipeline ---\n",
    "model = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# --- Apply 5-Fold Cross Validation ---\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')\n",
    "\n",
    "# --- Results ---\n",
    "print(\"\\nRÂ² scores for each fold:\", scores)\n",
    "print(\"Average RÂ² score:\", np.mean(scores))\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "print(\"\\nRMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2f8fd-5807-4fee-813b-c757c670e2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80aa7f-e2cb-4bf1-8f83-c0ccea936a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15:\n",
    "# --- Monthly Sales Forecast using Linear Regression and Cross-Validation ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Load Dataset ---\n",
    "# Replace with your file path if available\n",
    "# Example CSV columns: [\"ad_spend\", \"discount\", \"footfall\", \"sales\"]\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\sales_data.csv\")\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\\n\", df.head())\n",
    "print(\"\\nDataset Info:\\n\")\n",
    "print(df.info())\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
    "\n",
    "# --- Features and Target ---\n",
    "X = df[['ad_spend', 'discount', 'footfall']]\n",
    "y = df['sales']\n",
    "\n",
    "# --- Standardize the features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Define Linear Regression model ---\n",
    "model = LinearRegression()\n",
    "\n",
    "# --- 5-Fold Cross-Validation ---\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X_scaled, y, cv=kfold, scoring='r2')\n",
    "\n",
    "# --- Display Cross-Validation Results ---\n",
    "print(\"\\nRÂ² Scores for each fold:\", np.round(scores, 3))\n",
    "print(\"Average RÂ² Score:\", round(np.mean(scores), 3))\n",
    "\n",
    "# --- Fit model on entire data ---\n",
    "model.fit(X_scaled, y)\n",
    "y_pred = model.predict(X_scaled)\n",
    "\n",
    "# --- Evaluate Model ---\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "print(\"\\nModel Evaluation (Full Dataset):\")\n",
    "print(\"RÂ² Score:\", round(r2_score(y, y_pred), 3))\n",
    "print(\"RMSE:\", round(rmse, 3))\n",
    "print(\"MAE:\", round(mae, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25624804-cf3f-44ad-9bcc-7ee4e053e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16:\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\spam_data.csv\")   # rename if needed\n",
    "print(df.head())\n",
    "\n",
    "# Assuming columns: ['text', 'label'] where label is 'spam' or 'ham'\n",
    "X = df['text']\n",
    "y = df['label'].map({'ham':0, 'spam':1})  # convert to 0/1\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Text to numbers\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f46a4-681a-489a-afd5-f9ec5d5f334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\spam_data.csv\")\n",
    "X = df['text']\n",
    "y = df['label'].map({'ham':0, 'spam':1})\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert text to word counts\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Calculate priors\n",
    "spam_docs = X_train_vec[y_train == 1]\n",
    "ham_docs = X_train_vec[y_train == 0]\n",
    "P_spam = len(spam_docs.toarray()) / len(X_train)\n",
    "P_ham = len(ham_docs.toarray()) / len(X_train)\n",
    "\n",
    "# Calculate likelihoods\n",
    "spam_word_count = np.sum(spam_docs.toarray(), axis=0) + 1\n",
    "ham_word_count = np.sum(ham_docs.toarray(), axis=0) + 1\n",
    "total_spam_words = np.sum(spam_word_count)\n",
    "total_ham_words = np.sum(ham_word_count)\n",
    "\n",
    "# Prediction\n",
    "def predict_naive_bayes(X_vec):\n",
    "    preds = []\n",
    "    for x in X_vec:\n",
    "        x = x.toarray()[0]\n",
    "        log_spam = np.sum(x * np.log(spam_word_count / total_spam_words)) + np.log(P_spam)\n",
    "        log_ham = np.sum(x * np.log(ham_word_count / total_ham_words)) + np.log(P_ham)\n",
    "        preds.append(1 if log_spam > log_ham else 0)\n",
    "    return np.array(preds)\n",
    "\n",
    "y_pred = predict_naive_bayes(X_test_vec)\n",
    "\n",
    "# Accuracy\n",
    "acc = np.mean(y_pred == y_test.to_numpy())\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80649012-214c-4c44-a5e2-049c55b3ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18\n",
    "# 18:\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\spam_data.csv\")\n",
    "df['label'] = df['label'].map({'ham':0, 'spam':1})\n",
    "\n",
    "# Handle class imbalance using oversampling\n",
    "majority = df[df.label == 0]\n",
    "minority = df[df.label == 1]\n",
    "minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=0)\n",
    "df_balanced = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['text'], df_balanced['label'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_vec, y_train)\n",
    "y_pred = svm.predict(X_test_vec)\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a774c-60ff-4f46-9f1c-0fa5ab2788c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\spam_data.csv\")\n",
    "df['label'] = df['label'].map({'ham':-1, 'spam':1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert to numeric\n",
    "vectorizer = CountVectorizer(max_features=500)\n",
    "X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_vec = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# SVM from scratch (simple linear)\n",
    "class SVM:\n",
    "    def __init__(self, lr=0.001, lambda_param=0.01, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y[idx]))\n",
    "                    self.b -= self.lr * y[idx]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.w) - self.b)\n",
    "\n",
    "# Train and test\n",
    "svm = SVM()\n",
    "svm.fit(X_train_vec, y_train.to_numpy())\n",
    "pred = svm.predict(X_test_vec)\n",
    "\n",
    "# Accuracy\n",
    "acc = np.mean(pred == y_test.to_numpy())\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff4d21-530c-41bb-af5d-2d6fdff4b929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22dfe3a-d751-44e9-b038-9f4391d23b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\student_performance.csv\")  # change path if needed\n",
    "print(df.head())\n",
    "\n",
    "# --- Select relevant columns ---\n",
    "X = df[['studytime', 'absences', 'G1']]   # example feature columns\n",
    "y = df['Pass']                             # target (Pass/Fail)\n",
    "\n",
    "# --- Encode target ---\n",
    "y = y.map({'Fail': -1, 'Pass': 1})  # convert to -1 and +1\n",
    "\n",
    "# --- Train-test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# --- Define Polynomial Kernel ---\n",
    "def polynomial_kernel(x1, x2, degree=3, c=1):\n",
    "    return (np.dot(x1, x2.T) + c) ** degree\n",
    "\n",
    "# --- Simple SVM from Scratch using Dual Formulation (Simplified) ---\n",
    "class SimpleSVM:\n",
    "    def __init__(self, C=1, kernel=polynomial_kernel, degree=3):\n",
    "        self.C = C\n",
    "        self.kernel = lambda x, y: kernel(x, y, degree)\n",
    "    \n",
    "    def fit(self, X, y, lr=0.001, n_iters=200):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.alpha = np.zeros(n_samples)\n",
    "        self.b = 0\n",
    "        K = self.kernel(X, X)\n",
    "        \n",
    "        for _ in range(n_iters):\n",
    "            for i in range(n_samples):\n",
    "                condition = y[i] * (np.sum(self.alpha * y * K[:, i]) + self.b) < 1\n",
    "                if condition:\n",
    "                    self.alpha[i] += lr\n",
    "                    self.b += lr * y[i]\n",
    "        \n",
    "        self.X, self.y = X, y\n",
    "\n",
    "    def predict(self, X):\n",
    "        K = self.kernel(X, self.X)\n",
    "        y_pred = np.sign(np.sum(self.alpha * self.y * K, axis=1) + self.b)\n",
    "        return y_pred\n",
    "\n",
    "# --- Train model ---\n",
    "svm = SimpleSVM(C=1, degree=3)\n",
    "svm.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "# --- Predict ---\n",
    "y_pred = svm.predict(X_test.to_numpy())\n",
    "\n",
    "# --- Evaluation ---\n",
    "print(\"\\nPrecision:\", precision_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred, pos_label=1))\n",
    "print(\"F1-Score :\", f1_score(y_test, y_pred, pos_label=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9500f-977f-4da6-bdf0-c9332aea84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21  Develop an SVM classifier from scratch using a Polynomial Kernel on the Breast Cancer Wisconsin to \n",
    "# distinguish between  benign and malignant tumors. \n",
    "# Evaluate the classifier using a confusion matrix and ROC curve to analyze diagnostic accuracy.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# --- Step 1: Load Dataset ---\n",
    "df = pd.read_csv(r\"C:\\Users\\Documents\\AIML\\breast_cancer.csv\")\n",
    "print(\"Dataset Loaded Successfully âœ…\")\n",
    "print(df.head())\n",
    "\n",
    "# --- Step 2: Preprocess Data ---\n",
    "# Assuming columns: ['id','diagnosis','feature1','feature2',...]\n",
    "df = df.drop(columns=['id'], errors='ignore')\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': -1})  # M=Malignant, B=Benign\n",
    "\n",
    "X = df.drop(columns=['diagnosis']).values\n",
    "y = df['diagnosis'].values\n",
    "\n",
    "# --- Normalize Features ---\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Step 3: Define Polynomial Kernel ---\n",
    "def polynomial_kernel(x1, x2, degree=3, c=1):\n",
    "    return (np.dot(x1, x2.T) + c) ** degree\n",
    "\n",
    "# --- Step 4: SVM from Scratch ---\n",
    "class SimpleSVM:\n",
    "    def __init__(self, lr=0.001, lambda_param=0.01, n_iters=1000, degree=3):\n",
    "        self.lr = lr\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.degree = degree\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.alpha = np.zeros(n_samples)\n",
    "        self.b = 0\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.K = polynomial_kernel(X, X, self.degree)\n",
    "\n",
    "        # Gradient descent training\n",
    "        for _ in range(self.n_iters):\n",
    "            for i in range(n_samples):\n",
    "                condition = y[i] * (np.sum(self.alpha * y * self.K[:, i]) + self.b) < 1\n",
    "                if condition:\n",
    "                    self.alpha[i] += self.lr\n",
    "                    self.b += self.lr * y[i]\n",
    "        print(\"âœ… SVM Training Completed\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        K_test = polynomial_kernel(X, self.X, self.degree)\n",
    "        y_pred = np.sign(np.dot(K_test, self.alpha * self.y) + self.b)\n",
    "        return y_pred\n",
    "\n",
    "# --- Step 5: Train Model ---\n",
    "svm = SimpleSVM(lr=0.0005, n_iters=500, degree=3)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# --- Step 6: Predictions ---\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# --- Step 7: Evaluation Metrics ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "# --- Accuracy ---\n",
    "acc = np.mean(y_pred == y_test)\n",
    "print(f\"\\nModel Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# --- Step 8: ROC Curve ---\n",
    "y_scores = np.dot(polynomial_kernel(X_test, X_train, degree=3), svm.alpha * svm.y) + svm.b\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"Polynomial SVM (AUC = {roc_auc:.2f})\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Breast Cancer Classification\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
